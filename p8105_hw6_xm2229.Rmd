---
title: "p8105_hw6_xm2229"
author: "Xiaoyue Ma"
date: "11/16/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1

Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

```{r}
library(tidyverse)
raw_bw = read_csv("data/birthweight.csv")
janitor::clean_names(raw_bw) %>%
  ## check for missing values
  skimr::skim()
```

convert some of the the numeric variables to factor variables as stated in the introduction.

```{r}
cleaned_bw = raw_bw %>%
  mutate(babysex = case_when(babysex == 1 ~ "male", 
                             babysex == 2 ~ "female"),
         frace = case_when(frace == 1 ~ "white",
                           frace == 2 ~ "black",
                           frace == 3 ~ "asian",
                           frace == 4 ~ "puerto rican", 
                           frace == 8 ~ "other",
                           frace == 9 ~ "unknown"),
         malform = case_when(malform == 0 ~ "absent",
                             malform == 1 ~ "present"),
         mrace = case_when(mrace == 1 ~ "white",
                           mrace == 2 ~ "black",
                           mrace == 3 ~ "asian",
                           mrace == 4 ~ "puerto rican", 
                           mrace == 8 ~ "other")) %>%
  mutate(babysex = forcats::fct_relevel(babysex, "male", "female"),
         frace = forcats::fct_relevel(frace, "white", "black","asian","puerto rican", "other","unknow"),
         malform = forcats::fct_relevel(malform, "absent", "present"),
         mrace = forcats::fct_relevel(mrace, "white", "black", "asian", "puerto rican"))

skimr::skim(cleaned_bw)
```

According to basic biology, it is hypothesized that the factors that might affect baby's birthweight are `bhead`, `blength`, `babysex`, `delwt`, `malform`, `mheight`, `smoken`, `wtgain`. From the plot below, we can see that there are a few extreme values that has very high residuals, which means that there are a few predictions that are off by a huge value.

```{r}
library('ggplot2')
fit = lm(bwt ~ bhead + blength + babysex + delwt + malform + mheight + smoken + wtgain, data = cleaned_bw)

modelr::add_predictions(cleaned_bw, fit) %>%
  modelr::add_residuals(fit) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point() + labs(title = "A plot of Residual against Fitted value for the hypothesized model") + xlab("Fitted Value") + ylab("Residuals")
```

Compare your model to two others:

* One using length at birth and gestational age as predictors (main effects only)
* One using head circumference, length, sex, and all interactions (including the three-way interaction) between these

The steps taken here is to use `crossv_mc` to split the dataset into training set and testing set and compare the RMSE (mean square error) to decide which one is better. According to the plot below, for the 100 cross validation samples generated randomly, the hypothsized model has overall the lowest root mean squared cross-validated prediction error. Therefore, the hypothsized model might be a better one.

```{r}
cv_df = modelr::crossv_mc(cleaned_bw, 100) %>%
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))

cv_result = cv_df %>%
  mutate(hypothsized = map(train, ~lm(bwt ~ bhead + blength + babysex + delwt + malform + mheight + smoken + wtgain, data = .x)),
         bg = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         interaction = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead:blength + blength:babysex + bhead:babysex, data = .x))) %>%
  mutate(rmse_hypothsized = map2_dbl(hypothsized, test, ~modelr::rmse(model = .x, data = .y)),
         rmse_bg = map2_dbl(bg, test, ~modelr::rmse(model = .x, data = .y)),
         rmse_interaction = map2_dbl(interaction, test, ~modelr::rmse(model = .x, data = .y)))
  
cv_result %>%
  select(starts_with("rmse")) %>%
  pivot_longer(
    everything(),
    names_to = "model",
    values_to =  "rmse",
    names_prefix = "rmse_") %>%
  mutate(model = fct_inorder(model)) %>%
  ggplot(aes(x = model, y = rmse)) + geom_violin() + scale_x_discrete(labels = c("hypotheszied model", "2 factors model", "3-way interaction model")) + xlab("Models") + ylab("Root mean squared error")
```

Moreover, we could also compare the mean RMSE of the 100 generated corss-validated samples for the three models in the following table. By verifying the table below, the hypothsized model has a lower RMSE on average.

```{r}
cv_result %>%
  select(starts_with("rmse")) %>%
  pivot_longer(
    everything(),
    names_to = "model",
    values_to =  "rmse",
    names_prefix = "rmse_") %>%
  group_by(model) %>%
  summarise(mean_rmse = mean(rmse)) %>% knitr::kable()
```

## Problem 2
